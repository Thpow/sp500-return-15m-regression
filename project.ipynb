{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84116bb1-d64b-4de2-ae6d-a3a05122e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "AI_COLORS = {'primary':'#8FBC8F','gold':'#DAA520','crypto':'#FF6347','accent':'#6B8E23','highlight':'#ADFF2F','dark':'#2F4F2F','neutral':'#F0FFF0'}\n",
    "kiwi_palette = [AI_COLORS['primary'], AI_COLORS['gold'], AI_COLORS['crypto'], AI_COLORS['accent'], AI_COLORS['highlight']]\n",
    "plt.style.use('default')\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(kiwi_palette)\n",
    "plt.rcParams.update({'figure.facecolor':AI_COLORS['neutral'],'figure.figsize':[12,8],'axes.facecolor':'white','axes.edgecolor':AI_COLORS['dark'],'axes.grid':True,'axes.titlecolor':AI_COLORS['dark'],'axes.titleweight':'bold','axes.titlesize':16,'axes.labelsize':12,'grid.color':AI_COLORS['primary'],'grid.alpha':0.3,'font.size':11,'xtick.color':AI_COLORS['dark'],'ytick.color':AI_COLORS['dark'],'legend.fontsize':10,'legend.frameon':True,'legend.facecolor':'white','legend.edgecolor':AI_COLORS['primary'],'lines.linewidth':2,'savefig.dpi':300,'savefig.bbox':'tight'})\n",
    "sns.set_context(\"notebook\", font_scale=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af472306-a415-48e9-b3fc-134401e492a1",
   "metadata": {},
   "source": [
    "# The Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ffcb0",
   "metadata": {},
   "source": [
    "Computation and automation has absolutely taken over the trading world. As a retail trader, your best bet is to bet on what the you think the automated trades will think, not what YOU actually think will happen. This puts you at a massive disadvantage and completely changes the way you have to approach the markets as a retail trader. Thats why It would give a competitive advantage to be able to see what your own automation and computation says to get an idea of what the big player's automation will do.\n",
    "\n",
    "The problem is how precisely could we classify single 15 minute candlesticks of the S&P 500. We will ultimately aim to project if the next 15 minute candlestick will be a reversal and to what degree. This would identify could entries for shorts and longs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0035fa-c231-4f8e-be55-ba15d773705d",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b1ed3-42ef-400f-84ec-e84fd5af9427",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "The quality of the data is absolutely crucial when predicting the market. Thats why instead of like last time where I built my own data set with a lot of preprocessing I opted to pay for a high quality financially sound source. Backtestmarket. This data is a snap shot of the S&P 500 every 15 minutes, giving enough data to reconstruct the candlestick you would see visually with your eyes, but in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758d0e1b",
   "metadata": {},
   "source": [
    "S&P 500 15m: https://www.backtestmarket.com/en/sp-500-15m\n",
    "\n",
    "Has open high low close volume in increments of 25 cent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be50556-2bc5-4109-9369-5031dd35a11c",
   "metadata": {},
   "source": [
    "## Data explanation\n",
    "Open: The price at which the S&P 500 opened for the 15 minute interval\n",
    "Close: The price at which the S&P 500 closed for the 15 minute interval\n",
    "High: The highest price during the 15 minute interval\n",
    "Low: The lowest price during the 15 minute interval\n",
    "Volume: The total volume of trades during the 15 minute interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ef561e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a532939-29b3-4c25-bb74-0b3cb36b23bd",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d42a2c",
   "metadata": {},
   "source": [
    "First I want to import the data of course. But while im at it, ill go ahead and cleanup it's formating be a dataframe I like. I will also take care of the date column making it a real datetime object and a single column for the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39eff89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01/04/2007;17:15:00;1430;1431;1429.75;1431;592</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/04/2007;17:30:00;1431;1431.5;1430.75;1430.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/04/2007;17:45:00;1430.5;1431;1430.25;1430.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/04/2007;18:00:00;1430.5;1430.75;1430.25;143...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/04/2007;18:15:00;1431;1432;1431;1431.25;561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/04/2007;18:30:00;1431;1431.25;1431;1431.25;80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      01/04/2007;17:15:00;1430;1431;1429.75;1431;592\n",
       "0  01/04/2007;17:30:00;1431;1431.5;1430.75;1430.7...\n",
       "1  01/04/2007;17:45:00;1430.5;1431;1430.25;1430.5...\n",
       "2  01/04/2007;18:00:00;1430.5;1430.75;1430.25;143...\n",
       "3     01/04/2007;18:15:00;1431;1432;1431;1431.25;561\n",
       "4   01/04/2007;18:30:00;1431;1431.25;1431;1431.25;80"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv('es-15m.csv')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81440f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-04-01 17:30:00</th>\n",
       "      <td>1431.0</td>\n",
       "      <td>1431.50</td>\n",
       "      <td>1430.75</td>\n",
       "      <td>1430.75</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-04-01 17:45:00</th>\n",
       "      <td>1430.5</td>\n",
       "      <td>1431.00</td>\n",
       "      <td>1430.25</td>\n",
       "      <td>1430.50</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-04-01 18:00:00</th>\n",
       "      <td>1430.5</td>\n",
       "      <td>1430.75</td>\n",
       "      <td>1430.25</td>\n",
       "      <td>1430.75</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-04-01 18:15:00</th>\n",
       "      <td>1431.0</td>\n",
       "      <td>1432.00</td>\n",
       "      <td>1431.00</td>\n",
       "      <td>1431.25</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-04-01 18:30:00</th>\n",
       "      <td>1431.0</td>\n",
       "      <td>1431.25</td>\n",
       "      <td>1431.00</td>\n",
       "      <td>1431.25</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Open     High      Low    Close  Volume\n",
       "DateTime                                                      \n",
       "2007-04-01 17:30:00  1431.0  1431.50  1430.75  1430.75     461\n",
       "2007-04-01 17:45:00  1430.5  1431.00  1430.25  1430.50     264\n",
       "2007-04-01 18:00:00  1430.5  1430.75  1430.25  1430.75      91\n",
       "2007-04-01 18:15:00  1431.0  1432.00  1431.00  1431.25     561\n",
       "2007-04-01 18:30:00  1431.0  1431.25  1431.00  1431.25      80"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split = raw_df.iloc[:, 0].str.split(';', expand=True)\n",
    "spx_df = pd.DataFrame({\n",
    "    'Date': data_split[0],\n",
    "    'Time': data_split[1],\n",
    "    'Open': pd.to_numeric(data_split[2]),\n",
    "    'High': pd.to_numeric(data_split[3]),\n",
    "    'Low': pd.to_numeric(data_split[4]),\n",
    "    'Close': pd.to_numeric(data_split[5]),\n",
    "    'Volume': pd.to_numeric(data_split[6])\n",
    "})\n",
    "\n",
    "# Create datetime column for index\n",
    "spx_df['DateTime'] = pd.to_datetime(spx_df['Date'] + ' ' + spx_df['Time'], format='%d/%m/%Y %H:%M:%S')\n",
    "spx_df = spx_df.set_index('DateTime').sort_index()\n",
    "\n",
    "# Drop original date/time columns\n",
    "spx_df = spx_df.drop(['Date', 'Time'], axis=1)\n",
    "spx_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
